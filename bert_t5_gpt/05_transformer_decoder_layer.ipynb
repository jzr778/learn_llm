{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51d27917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import Image\n",
    "# default: 100\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f90b5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os#环境代理设置\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cb6835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'bert-base-uncased'\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "config = AutoConfig.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf4faaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "text = 'time flies like an arrow'\n",
    "model_inputs = tokenizer(text, return_tensors='pt', add_special_tokens=False)\n",
    "input_embeddings = token_embedding(model_inputs['input_ids'])\n",
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "229138e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[27.1610,  0.7026,  0.1613, -0.9768, -1.0512],\n",
       "         [ 0.7026, 29.9493, -0.9095,  1.1273, -1.4273],\n",
       "         [ 0.1613, -0.9095, 27.4205,  0.1608,  0.5826],\n",
       "         [-0.9768,  1.1273,  0.1608, 29.4293,  1.8717],\n",
       "         [-1.0512, -1.4273,  0.5826,  1.8717, 30.7920]]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "q = k = v = input_embeddings\n",
    "# (1, 5, 768) * (1, 768, 5) => (1, 5, 5)\n",
    "scores = torch.bmm(q, k.transpose(1,2))/math.sqrt(k.size(-1))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7cbc0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = model_inputs['input_ids'].size(-1)\n",
    "# triangular lower（上三角的话，torch.triu，upper triangular）\n",
    "mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab9b5eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[27.1610,    -inf,    -inf,    -inf,    -inf],\n",
       "         [ 0.7026, 29.9493,    -inf,    -inf,    -inf],\n",
       "         [ 0.1613, -0.9095, 27.4205,    -inf,    -inf],\n",
       "         [-0.9768,  1.1273,  0.1608, 29.4293,    -inf],\n",
       "         [-1.0512, -1.4273,  0.5826,  1.8717, 30.7920]]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.masked_fill(mask==0, -float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7c7468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.tensor(-float('inf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66912440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 3.2302e-12, 1.8800e-12, 6.0240e-13, 5.5924e-13],\n",
       "         [1.9874e-13, 1.0000e+00, 3.9645e-14, 3.0392e-13, 2.3620e-14],\n",
       "         [1.4503e-12, 4.9711e-13, 1.0000e+00, 1.4497e-12, 2.2102e-12],\n",
       "         [6.2345e-14, 5.1123e-13, 1.9448e-13, 1.0000e+00, 1.0763e-12],\n",
       "         [1.4815e-14, 1.0170e-14, 7.5897e-14, 2.7549e-13, 1.0000e+00]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = F.softmax(scores, dim=-1)\n",
    "weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7079c",
   "metadata": {},
   "source": [
    "(masked)self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e786646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attn(q, k, v, maske=None):\n",
    "    dim_k = k.size(-1)\n",
    "    attn_scores = torch.bmm(q, k.transpose(1,2))/math.sqrt(dim_k)\n",
    "    if mask is not None:\n",
    "        scores.masked_fill(mask==0, -float('inf'))\n",
    "    attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "    print(attn_weights)\n",
    "    return torch.bmm(attn_weights,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ab2c9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000e+00, 3.2302e-12, 1.8800e-12, 6.0240e-13, 5.5924e-13],\n",
      "         [1.9874e-13, 1.0000e+00, 3.9645e-14, 3.0392e-13, 2.3620e-14],\n",
      "         [1.4503e-12, 4.9711e-13, 1.0000e+00, 1.4497e-12, 2.2102e-12],\n",
      "         [6.2345e-14, 5.1123e-13, 1.9448e-13, 1.0000e+00, 1.0763e-12],\n",
      "         [1.4815e-14, 1.0170e-14, 7.5897e-14, 2.7549e-13, 1.0000e+00]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3221,  0.5982, -0.6843,  ..., -0.7314, -0.3412, -1.0361],\n",
       "         [-0.0584,  1.5743,  0.1616,  ..., -0.1830,  0.6903,  0.4571],\n",
       "         [-0.0127, -0.0299, -0.6004,  ...,  0.5157, -0.1864, -0.2521],\n",
       "         [-0.5243, -0.5876,  0.5193,  ...,  1.9051,  0.3476,  1.1640],\n",
       "         [ 1.6745,  0.0067,  0.0389,  ..., -0.0784,  0.3701,  1.2834]]],\n",
       "       grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_dot_product_attn(q, k, v, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3cf02d",
   "metadata": {},
   "source": [
    "源码分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0422873",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "# from encoder output\n",
    "# (seq_len, batch_size, hidden_dim)\n",
    "memory = torch.rand(10,32,512)\n",
    "# 因为seq2seq的输入输出长度可能不同，如中英翻译\n",
    "target = torch.rand(20,32,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a3a9d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoderLayer(\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (multihead_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (dropout3): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTroch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os#ÁéØÂ¢É‰ª£ÁêÜËÆæÁΩÆ\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangzirou/data/miniconda3/envs/PyTroch/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillTrainingArguments(TrainingArguments):\n",
    "    def __init__(self, *args, alpha=0.5, temperature=2., **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher_model = teacher_model\n",
    "    \n",
    "    # def compute_loss(self, model, inputs, return_outputs=False):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        s_output = model(**inputs)\n",
    "        s_ce = s_output.loss #‰∫§ÂèâÁÜµÊçüÂ§±\n",
    "        s_logits = s_output.logits\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            t_output = self.teacher_model(**inputs)\n",
    "            t_logits = t_output.logits\n",
    "        \n",
    "        loss_kl_fct = nn.KLDivLoss(reduction='batchmean')\n",
    "        loss_kd = self.args.temperature**2 * loss_kl_fct(F.log_softmax(s_logits/self.args.temperature, dim=-1), \n",
    "                                                        F.softmax(t_logits/self.args.temperature, dim=-1))\n",
    "        loss = self.args.alpha * s_ce + (1-self.args.alpha) * loss_kd\n",
    "        return (loss, s_output) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "clinc = load_dataset(\"clinc_oos\", \"plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 15250\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 3100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 5500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'intent'],\n",
       "    num_rows: 15250\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinc['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['what expression would i use to say i love you if i were an italian',\n",
       "  \"can you tell me how to say 'i do not speak much spanish', in spanish\",\n",
       "  \"what is the equivalent of, 'life is good' in french\",\n",
       "  \"tell me how to say, 'it is a beautiful morning' in italian\",\n",
       "  'if i were mongolian, how would i say that i am a tourist',\n",
       "  \"how do i say 'hotel' in finnish\",\n",
       "  \"i need you to translate the sentence, 'we will be there soon' into portuguese\",\n",
       "  'please tell me how to ask for a taxi in french',\n",
       "  \"can you tell me how i would say, 'more bread please' in french\",\n",
       "  \"what is the correct way to say 'i am a visitor' in french\"],\n",
       " 'intent': [61, 61, 61, 61, 61, 61, 61, 61, 61, 61]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinc['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents = clinc['train'].features['intent']\n",
    "num_labels = intents.num_classes\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student model ÂàùÂßãÂåñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "s_ckpt = 'distilbert-base-uncased'\n",
    "s_tokenizer = AutoTokenizer.from_pretrained(s_ckpt)\n",
    "\n",
    "t_ckpt = 'transformersbook/bert-base-uncased-finetuned-clinc'\n",
    "t_model = AutoModelForSequenceClassification.from_pretrained(t_ckpt, num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_func(dataset):\n",
    "    return s_tokenizer(dataset['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "# ÂàõÂª∫Êñ∞ÁöÑÊï∞ÊçÆÈõÜÂ≠óÂÖ∏\n",
    "myclinc = DatasetDict()\n",
    "\n",
    "# ÈááÊ†∑ÊØî‰æã‰∏∫ 1%\n",
    "sampling_rate = 0.01\n",
    "\n",
    "# ÂØπÊØè‰∏™Â≠êÈõÜËøõË°åÈááÊ†∑\n",
    "for split in clinc.keys():\n",
    "    dataset = clinc[split]\n",
    "    # ‰ΩøÁî® train_test_split ÊñπÊ≥ïËøõË°åÈááÊ†∑ÔºåÂè™‰øùÁïôÊµãËØïÈõÜÈÉ®ÂàÜ\n",
    "    sampled_dataset = dataset.train_test_split(test_size=sampling_rate, seed=42)['test']\n",
    "    myclinc[split] = sampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 153\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 31\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 55\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myclinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd3f41e948744109fac1fc1a2034452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 15250\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinc_enc = clinc.map(function=lambda batch:s_tokenizer(batch['text'], truncation=True),\n",
    "                      batched=True,\n",
    "                      remove_columns=['text'])\n",
    "clinc_enc = clinc_enc.rename_columns({'intent': 'labels'})\n",
    "clinc_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangzirou/.local/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "s_training_args = DistillTrainingArguments(output_dir='distilbert-base-uncased-ft-clinc', \n",
    "                                           evaluation_strategy='epoch', num_train_epochs=5, \n",
    "                                           learning_rate=3e-4, \n",
    "                                           per_device_train_batch_size=batch_size, \n",
    "                                           per_device_eval_batch_size=batch_size, \n",
    "                                           alpha=0.5, weight_decay=0.01, \n",
    "                                           logging_strategy='epoch',\n",
    "                                           push_to_hub=False)\n",
    "s_config = AutoConfig.from_pretrained(s_ckpt, num_labels=num_labels, \n",
    "                                      id2label=t_model.config.id2label, label2id=t_model.config.label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"restaurant_reviews\",\n",
       "    \"1\": \"nutrition_info\",\n",
       "    \"2\": \"account_blocked\",\n",
       "    \"3\": \"oil_change_how\",\n",
       "    \"4\": \"time\",\n",
       "    \"5\": \"weather\",\n",
       "    \"6\": \"redeem_rewards\",\n",
       "    \"7\": \"interest_rate\",\n",
       "    \"8\": \"gas_type\",\n",
       "    \"9\": \"accept_reservations\",\n",
       "    \"10\": \"smart_home\",\n",
       "    \"11\": \"user_name\",\n",
       "    \"12\": \"report_lost_card\",\n",
       "    \"13\": \"repeat\",\n",
       "    \"14\": \"whisper_mode\",\n",
       "    \"15\": \"what_are_your_hobbies\",\n",
       "    \"16\": \"order\",\n",
       "    \"17\": \"jump_start\",\n",
       "    \"18\": \"schedule_meeting\",\n",
       "    \"19\": \"meeting_schedule\",\n",
       "    \"20\": \"freeze_account\",\n",
       "    \"21\": \"what_song\",\n",
       "    \"22\": \"meaning_of_life\",\n",
       "    \"23\": \"restaurant_reservation\",\n",
       "    \"24\": \"traffic\",\n",
       "    \"25\": \"make_call\",\n",
       "    \"26\": \"text\",\n",
       "    \"27\": \"bill_balance\",\n",
       "    \"28\": \"improve_credit_score\",\n",
       "    \"29\": \"change_language\",\n",
       "    \"30\": \"no\",\n",
       "    \"31\": \"measurement_conversion\",\n",
       "    \"32\": \"timer\",\n",
       "    \"33\": \"flip_coin\",\n",
       "    \"34\": \"do_you_have_pets\",\n",
       "    \"35\": \"balance\",\n",
       "    \"36\": \"tell_joke\",\n",
       "    \"37\": \"last_maintenance\",\n",
       "    \"38\": \"exchange_rate\",\n",
       "    \"39\": \"uber\",\n",
       "    \"40\": \"car_rental\",\n",
       "    \"41\": \"credit_limit\",\n",
       "    \"42\": \"oos\",\n",
       "    \"43\": \"shopping_list\",\n",
       "    \"44\": \"expiration_date\",\n",
       "    \"45\": \"routing\",\n",
       "    \"46\": \"meal_suggestion\",\n",
       "    \"47\": \"tire_change\",\n",
       "    \"48\": \"todo_list\",\n",
       "    \"49\": \"card_declined\",\n",
       "    \"50\": \"rewards_balance\",\n",
       "    \"51\": \"change_accent\",\n",
       "    \"52\": \"vaccines\",\n",
       "    \"53\": \"reminder_update\",\n",
       "    \"54\": \"food_last\",\n",
       "    \"55\": \"change_ai_name\",\n",
       "    \"56\": \"bill_due\",\n",
       "    \"57\": \"who_do_you_work_for\",\n",
       "    \"58\": \"share_location\",\n",
       "    \"59\": \"international_visa\",\n",
       "    \"60\": \"calendar\",\n",
       "    \"61\": \"translate\",\n",
       "    \"62\": \"carry_on\",\n",
       "    \"63\": \"book_flight\",\n",
       "    \"64\": \"insurance_change\",\n",
       "    \"65\": \"todo_list_update\",\n",
       "    \"66\": \"timezone\",\n",
       "    \"67\": \"cancel_reservation\",\n",
       "    \"68\": \"transactions\",\n",
       "    \"69\": \"credit_score\",\n",
       "    \"70\": \"report_fraud\",\n",
       "    \"71\": \"spending_history\",\n",
       "    \"72\": \"directions\",\n",
       "    \"73\": \"spelling\",\n",
       "    \"74\": \"insurance\",\n",
       "    \"75\": \"what_is_your_name\",\n",
       "    \"76\": \"reminder\",\n",
       "    \"77\": \"where_are_you_from\",\n",
       "    \"78\": \"distance\",\n",
       "    \"79\": \"payday\",\n",
       "    \"80\": \"flight_status\",\n",
       "    \"81\": \"find_phone\",\n",
       "    \"82\": \"greeting\",\n",
       "    \"83\": \"alarm\",\n",
       "    \"84\": \"order_status\",\n",
       "    \"85\": \"confirm_reservation\",\n",
       "    \"86\": \"cook_time\",\n",
       "    \"87\": \"damaged_card\",\n",
       "    \"88\": \"reset_settings\",\n",
       "    \"89\": \"pin_change\",\n",
       "    \"90\": \"replacement_card_duration\",\n",
       "    \"91\": \"new_card\",\n",
       "    \"92\": \"roll_dice\",\n",
       "    \"93\": \"income\",\n",
       "    \"94\": \"taxes\",\n",
       "    \"95\": \"date\",\n",
       "    \"96\": \"who_made_you\",\n",
       "    \"97\": \"pto_request\",\n",
       "    \"98\": \"tire_pressure\",\n",
       "    \"99\": \"how_old_are_you\",\n",
       "    \"100\": \"rollover_401k\",\n",
       "    \"101\": \"pto_request_status\",\n",
       "    \"102\": \"how_busy\",\n",
       "    \"103\": \"application_status\",\n",
       "    \"104\": \"recipe\",\n",
       "    \"105\": \"calendar_update\",\n",
       "    \"106\": \"play_music\",\n",
       "    \"107\": \"yes\",\n",
       "    \"108\": \"direct_deposit\",\n",
       "    \"109\": \"credit_limit_change\",\n",
       "    \"110\": \"gas\",\n",
       "    \"111\": \"pay_bill\",\n",
       "    \"112\": \"ingredients_list\",\n",
       "    \"113\": \"lost_luggage\",\n",
       "    \"114\": \"goodbye\",\n",
       "    \"115\": \"what_can_i_ask_you\",\n",
       "    \"116\": \"book_hotel\",\n",
       "    \"117\": \"are_you_a_bot\",\n",
       "    \"118\": \"next_song\",\n",
       "    \"119\": \"change_speed\",\n",
       "    \"120\": \"plug_type\",\n",
       "    \"121\": \"maybe\",\n",
       "    \"122\": \"w2\",\n",
       "    \"123\": \"oil_change_when\",\n",
       "    \"124\": \"thank_you\",\n",
       "    \"125\": \"shopping_list_update\",\n",
       "    \"126\": \"pto_balance\",\n",
       "    \"127\": \"order_checks\",\n",
       "    \"128\": \"travel_alert\",\n",
       "    \"129\": \"fun_fact\",\n",
       "    \"130\": \"sync_device\",\n",
       "    \"131\": \"schedule_maintenance\",\n",
       "    \"132\": \"apr\",\n",
       "    \"133\": \"transfer\",\n",
       "    \"134\": \"ingredient_substitution\",\n",
       "    \"135\": \"calories\",\n",
       "    \"136\": \"current_location\",\n",
       "    \"137\": \"international_fees\",\n",
       "    \"138\": \"calculator\",\n",
       "    \"139\": \"definition\",\n",
       "    \"140\": \"next_holiday\",\n",
       "    \"141\": \"update_playlist\",\n",
       "    \"142\": \"mpg\",\n",
       "    \"143\": \"min_payment\",\n",
       "    \"144\": \"change_user_name\",\n",
       "    \"145\": \"restaurant_suggestion\",\n",
       "    \"146\": \"travel_notification\",\n",
       "    \"147\": \"cancel\",\n",
       "    \"148\": \"pto_used\",\n",
       "    \"149\": \"travel_suggestion\",\n",
       "    \"150\": \"change_volume\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"accept_reservations\": 9,\n",
       "    \"account_blocked\": 2,\n",
       "    \"alarm\": 83,\n",
       "    \"application_status\": 103,\n",
       "    \"apr\": 132,\n",
       "    \"are_you_a_bot\": 117,\n",
       "    \"balance\": 35,\n",
       "    \"bill_balance\": 27,\n",
       "    \"bill_due\": 56,\n",
       "    \"book_flight\": 63,\n",
       "    \"book_hotel\": 116,\n",
       "    \"calculator\": 138,\n",
       "    \"calendar\": 60,\n",
       "    \"calendar_update\": 105,\n",
       "    \"calories\": 135,\n",
       "    \"cancel\": 147,\n",
       "    \"cancel_reservation\": 67,\n",
       "    \"car_rental\": 40,\n",
       "    \"card_declined\": 49,\n",
       "    \"carry_on\": 62,\n",
       "    \"change_accent\": 51,\n",
       "    \"change_ai_name\": 55,\n",
       "    \"change_language\": 29,\n",
       "    \"change_speed\": 119,\n",
       "    \"change_user_name\": 144,\n",
       "    \"change_volume\": 150,\n",
       "    \"confirm_reservation\": 85,\n",
       "    \"cook_time\": 86,\n",
       "    \"credit_limit\": 41,\n",
       "    \"credit_limit_change\": 109,\n",
       "    \"credit_score\": 69,\n",
       "    \"current_location\": 136,\n",
       "    \"damaged_card\": 87,\n",
       "    \"date\": 95,\n",
       "    \"definition\": 139,\n",
       "    \"direct_deposit\": 108,\n",
       "    \"directions\": 72,\n",
       "    \"distance\": 78,\n",
       "    \"do_you_have_pets\": 34,\n",
       "    \"exchange_rate\": 38,\n",
       "    \"expiration_date\": 44,\n",
       "    \"find_phone\": 81,\n",
       "    \"flight_status\": 80,\n",
       "    \"flip_coin\": 33,\n",
       "    \"food_last\": 54,\n",
       "    \"freeze_account\": 20,\n",
       "    \"fun_fact\": 129,\n",
       "    \"gas\": 110,\n",
       "    \"gas_type\": 8,\n",
       "    \"goodbye\": 114,\n",
       "    \"greeting\": 82,\n",
       "    \"how_busy\": 102,\n",
       "    \"how_old_are_you\": 99,\n",
       "    \"improve_credit_score\": 28,\n",
       "    \"income\": 93,\n",
       "    \"ingredient_substitution\": 134,\n",
       "    \"ingredients_list\": 112,\n",
       "    \"insurance\": 74,\n",
       "    \"insurance_change\": 64,\n",
       "    \"interest_rate\": 7,\n",
       "    \"international_fees\": 137,\n",
       "    \"international_visa\": 59,\n",
       "    \"jump_start\": 17,\n",
       "    \"last_maintenance\": 37,\n",
       "    \"lost_luggage\": 113,\n",
       "    \"make_call\": 25,\n",
       "    \"maybe\": 121,\n",
       "    \"meal_suggestion\": 46,\n",
       "    \"meaning_of_life\": 22,\n",
       "    \"measurement_conversion\": 31,\n",
       "    \"meeting_schedule\": 19,\n",
       "    \"min_payment\": 143,\n",
       "    \"mpg\": 142,\n",
       "    \"new_card\": 91,\n",
       "    \"next_holiday\": 140,\n",
       "    \"next_song\": 118,\n",
       "    \"no\": 30,\n",
       "    \"nutrition_info\": 1,\n",
       "    \"oil_change_how\": 3,\n",
       "    \"oil_change_when\": 123,\n",
       "    \"oos\": 42,\n",
       "    \"order\": 16,\n",
       "    \"order_checks\": 127,\n",
       "    \"order_status\": 84,\n",
       "    \"pay_bill\": 111,\n",
       "    \"payday\": 79,\n",
       "    \"pin_change\": 89,\n",
       "    \"play_music\": 106,\n",
       "    \"plug_type\": 120,\n",
       "    \"pto_balance\": 126,\n",
       "    \"pto_request\": 97,\n",
       "    \"pto_request_status\": 101,\n",
       "    \"pto_used\": 148,\n",
       "    \"recipe\": 104,\n",
       "    \"redeem_rewards\": 6,\n",
       "    \"reminder\": 76,\n",
       "    \"reminder_update\": 53,\n",
       "    \"repeat\": 13,\n",
       "    \"replacement_card_duration\": 90,\n",
       "    \"report_fraud\": 70,\n",
       "    \"report_lost_card\": 12,\n",
       "    \"reset_settings\": 88,\n",
       "    \"restaurant_reservation\": 23,\n",
       "    \"restaurant_reviews\": 0,\n",
       "    \"restaurant_suggestion\": 145,\n",
       "    \"rewards_balance\": 50,\n",
       "    \"roll_dice\": 92,\n",
       "    \"rollover_401k\": 100,\n",
       "    \"routing\": 45,\n",
       "    \"schedule_maintenance\": 131,\n",
       "    \"schedule_meeting\": 18,\n",
       "    \"share_location\": 58,\n",
       "    \"shopping_list\": 43,\n",
       "    \"shopping_list_update\": 125,\n",
       "    \"smart_home\": 10,\n",
       "    \"spelling\": 73,\n",
       "    \"spending_history\": 71,\n",
       "    \"sync_device\": 130,\n",
       "    \"taxes\": 94,\n",
       "    \"tell_joke\": 36,\n",
       "    \"text\": 26,\n",
       "    \"thank_you\": 124,\n",
       "    \"time\": 4,\n",
       "    \"timer\": 32,\n",
       "    \"timezone\": 66,\n",
       "    \"tire_change\": 47,\n",
       "    \"tire_pressure\": 98,\n",
       "    \"todo_list\": 48,\n",
       "    \"todo_list_update\": 65,\n",
       "    \"traffic\": 24,\n",
       "    \"transactions\": 68,\n",
       "    \"transfer\": 133,\n",
       "    \"translate\": 61,\n",
       "    \"travel_alert\": 128,\n",
       "    \"travel_notification\": 146,\n",
       "    \"travel_suggestion\": 149,\n",
       "    \"uber\": 39,\n",
       "    \"update_playlist\": 141,\n",
       "    \"user_name\": 11,\n",
       "    \"vaccines\": 52,\n",
       "    \"w2\": 122,\n",
       "    \"weather\": 5,\n",
       "    \"what_are_your_hobbies\": 15,\n",
       "    \"what_can_i_ask_you\": 115,\n",
       "    \"what_is_your_name\": 75,\n",
       "    \"what_song\": 21,\n",
       "    \"where_are_you_from\": 77,\n",
       "    \"whisper_mode\": 14,\n",
       "    \"who_do_you_work_for\": 57,\n",
       "    \"who_made_you\": 96,\n",
       "    \"yes\": 107\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_init():    \n",
    "    return AutoModelForSequenceClassification.from_pretrained(s_ckpt, config=s_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy_score = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer ÈáçË¶ÅÁöÑÂõûË∞ÉÂáΩÊï∞ÔºåÈùûÊàêÂëòÂáΩÊï∞\n",
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return accuracy_score.compute(references=labels, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4087169/214101092.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DistillTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/jiangzirou/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='265' max='265' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [265/265 02:09, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.625300</td>\n",
       "      <td>0.494599</td>\n",
       "      <td>0.911613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>0.321383</td>\n",
       "      <td>0.943226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.288618</td>\n",
       "      <td>0.949032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.279677</td>\n",
       "      <td>0.950323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.196300</td>\n",
       "      <td>0.275943</td>\n",
       "      <td>0.951613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangzirou/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jiangzirou/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jiangzirou/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jiangzirou/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jiangzirou/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=265, training_loss=0.518394628560768, metrics={'train_runtime': 129.9044, 'train_samples_per_second': 586.97, 'train_steps_per_second': 2.04, 'total_flos': 490522246969356.0, 'train_loss': 0.518394628560768, 'epoch': 5.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_trainer = DistillTrainer(model_init=student_init, teacher_model=t_model, args=s_training_args, \n",
    "                                 train_dataset=clinc_enc['train'], eval_dataset=clinc_enc['validation'], \n",
    "                                 compute_metrics=compute_metrics, tokenizer=s_tokenizer)\n",
    "distill_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gpu = 9\n",
      "local_rank = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"n_gpu =\", s_training_args.n_gpu)\n",
    "print(\"local_rank =\", s_training_args.local_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil(15250/(32*9))*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f79b8e4bfc48d383223d35a4605df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486b8e74a3b8443e9097cde4e83f2b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb994bcf83224032a7b37b0434f5541f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...-uncased-ft-clinc/model.safetensors:   1%|          | 2.30MB /  268MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63756e25a8e4a3386c1e85f43f6e8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...-uncased-ft-clinc/training_args.bin:   8%|8         |   437B / 5.30kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jzr778/distilbert-base-uncased-ft-clinc/commit/25ee841fe3713d9887845368246ddb2030a38441', commit_message='finetune completed', commit_description='', oid='25ee841fe3713d9887845368246ddb2030a38441', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jzr778/distilbert-base-uncased-ft-clinc', endpoint='https://huggingface.co', repo_type='model', repo_id='jzr778/distilbert-base-uncased-ft-clinc'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_ckpt = 'distilbert-base-uncased-ft-clinc'\n",
    "distill_trainer.push_to_hub('finetune completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "clf = pipeline(\"text-classification\",\n",
    "               model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "               device=device,\n",
    "               batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinc_ft = myclinc.map(function=lambda batch:s_tokenizer(batch['text'], truncation=True),\n",
    "                      batched=True,\n",
    "                      remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'intent'],\n",
       "    num_rows: 5500\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinc['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998599290847778},\n",
       " {'label': 'POSITIVE', 'score': 0.5255300998687744},\n",
       " {'label': 'NEGATIVE', 'score': 0.9657660126686096},\n",
       " {'label': 'NEGATIVE', 'score': 0.9832302927970886},\n",
       " {'label': 'NEGATIVE', 'score': 0.9788899421691895}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(clinc['test']['text'][5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTroch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

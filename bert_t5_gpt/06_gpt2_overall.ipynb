{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d3c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os#环境代理设置\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58133208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import Image\n",
    "# default: 100\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096f49c8",
   "metadata": {},
   "source": [
    "gpt</br>\n",
    "| model        | 参数量 | hidden dim     | block 数量 |\n",
    "|--------------|--------|----------------|------------|\n",
    "| gpt2         | 124M   | 768 (64×12)    | 12         |\n",
    "| gpt2-medium  | 355M   | 1024 (64×16)   | 24         |\n",
    "| gpt2-large   | 774M   | 1280 (64×20)   | 36         |\n",
    "| gpt2-xl      | 1.56B  | 1600 (64×25)   | 48         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e412bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers_utils import get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc4d196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangzirou/data/miniconda3/envs/PyTroch/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = 'gpt2-xl'\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207819b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,557,611,200\n"
     ]
    }
   ],
   "source": [
    "# model_clm = AutoModelForCausalLM.from_pretrained(model_ckpt)\n",
    "print(format(get_params(model), ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b5badbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2-xl\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1600,\n",
       "  \"n_head\": 25,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 48,\n",
       "  \"n_positions\": 1024,\n",
       "  \"output_past\": true,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2adef65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 1600)\n",
       "  (wpe): Embedding(1024, 1600)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-47): 48 x GPT2Block(\n",
       "      (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2SdpaAttention(\n",
       "        (c_attn): Conv1D(nf=4800, nx=1600)\n",
       "        (c_proj): Conv1D(nf=1600, nx=1600)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D(nf=6400, nx=1600)\n",
       "        (c_proj): Conv1D(nf=1600, nx=6400)\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dbd709",
   "metadata": {},
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42adfa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2-xl', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48398b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08234506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88f6cf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50256]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c51c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(50256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa355b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496]\n",
      "[31373]\n",
      "[23748]\n",
      " hello\n",
      "[23748]\n",
      "[220, 23748]\n",
      "[220, 220, 23748]\n"
     ]
    }
   ],
   "source": [
    "# 大小写敏感\n",
    "print(tokenizer.encode('Hello'))\n",
    "print(tokenizer.encode('hello'))\n",
    "print(tokenizer.encode(' hello'))\n",
    "print(tokenizer.decode(23748))\n",
    "print(tokenizer.encode(' hello'))\n",
    "print(tokenizer.encode('  hello'))\n",
    "print(tokenizer.encode('   hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56eb9582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3666, 4004, 3124, 318, 8262, 260, 1904], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('My favorite color is chartreuse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "025446cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8262, 260, 1904]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(' chartreuse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3de13",
   "metadata": {},
   "source": [
    "### attention_mask\n",
    "- 更好地构造结构化，批次化输入（tensor，shape一定）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f874b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "sentences = [\"It will rain in the\",\n",
    "            \"I want to eat a big bowl of\",\n",
    "            \"My dog is\"]\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c43a49b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1026,   481,  6290,   287,   262, 50256, 50256, 50256],\n",
       "        [   40,   765,   284,  4483,   257,  1263,  9396,   286],\n",
       "        [ 3666,  3290,   318, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc6b81",
   "metadata": {},
   "source": [
    "### forward\n",
    "- GPT2Model\n",
    "    - wte: word token embedding\n",
    "    - wpe: word position embedding\n",
    "- LMHead\n",
    "    - mlp: hidden_state => vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98a76a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'gpt2-xl'\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "model_clm = AutoModelForCausalLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e076987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 1600)\n",
       "  (wpe): Embedding(1024, 1600)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-47): 48 x GPT2Block(\n",
       "      (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2SdpaAttention(\n",
       "        (c_attn): Conv1D(nf=4800, nx=1600)\n",
       "        (c_proj): Conv1D(nf=1600, nx=1600)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D(nf=6400, nx=1600)\n",
       "        (c_proj): Conv1D(nf=1600, nx=6400)\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596b848",
   "metadata": {},
   "source": [
    "model_clm(GPT2LMHeadModel)\n",
    "- GPT2Model\n",
    "- lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfc96319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1600)\n",
       "    (wpe): Embedding(1024, 1600)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-47): 48 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=4800, nx=1600)\n",
       "          (c_proj): Conv1D(nf=1600, nx=1600)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=6400, nx=1600)\n",
       "          (c_proj): Conv1D(nf=1600, nx=6400)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ed8de61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  32,  890,  890,  640, 2084]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 大小写是不同的token，\n",
    "# 空格也是token\n",
    "input_txt = \"A long long time ago\"\n",
    "model_inputs = tokenizer(input_txt, return_tensors='pt')\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "302182b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = model_inputs['input_ids'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97bfbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_clm(input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b9ad963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 50257])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abf704",
   "metadata": {},
   "source": [
    "model.transformer()</br>\n",
    "`(transformer): GPT2Model`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d31534",
   "metadata": {},
   "source": [
    "- 设为评估模式.eval()\n",
    "    - Dropout 层：在训练模式下会随机丢弃部分神经元，而在评估模式下会保留所有神经元。\n",
    "    - BatchNorm 层：在训练模式下会使用当前 batch 的均值和方差，而在评估模式下会使用训练阶段累计的均值和方差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61615cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1600)\n",
       "    (wpe): Embedding(1024, 1600)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-47): 48 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=4800, nx=1600)\n",
       "          (c_proj): Conv1D(nf=1600, nx=1600)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=6400, nx=1600)\n",
       "          (c_proj): Conv1D(nf=1600, nx=6400)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clm.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98c5d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model_clm.transformer(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e49ab959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5478,  0.0327,  0.7692,  ..., -4.5986,  0.2638,  0.1780],\n",
       "         [-1.0570, -0.8408,  0.8223,  ..., -1.3309,  1.0921,  0.7939],\n",
       "         [-0.5805, -1.1760,  0.4954,  ..., -1.3462,  1.2957,  1.2741],\n",
       "         [-0.2789, -1.5347,  0.6579,  ..., -1.6087,  1.1029,  0.9785],\n",
       "         [ 0.2617,  0.0104,  0.6141,  ..., -1.6620,  1.4646,  0.6588]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "975fb0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1600])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e393e61",
   "metadata": {},
   "source": [
    "自定义（model.transformer()）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab49c0f",
   "metadata": {},
   "source": [
    "input_ids = input_ids.view(-1, input_shape[-1])  \n",
    "- [4, 2, 512] ->[8, 512]\n",
    "- 为了把多个“选择”或“样本”展平成一个批次，以便可以一次性喂给模型处理，提高效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f424f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids.shape: torch.Size([1, 5])\n",
      "output_shape: torch.Size([1, 5, 1600])\n",
      "head_mask: [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "0-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 0.0561, -0.0133, -0.0379,  ...,  0.0304,  0.1525,  0.0057],\n",
      "         [-0.1368,  0.0144,  0.0026,  ...,  0.0229, -0.2616, -0.0106],\n",
      "         [-0.1034,  0.0086,  0.0022,  ..., -0.0359, -0.1381, -0.0129],\n",
      "         [-0.0525, -0.0773, -0.0579,  ..., -0.0693, -0.1473,  0.0524],\n",
      "         [ 0.0348, -0.0597,  0.0203,  ...,  0.0646, -0.0895,  0.0079]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "1-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 0.2438,  0.3277,  0.0373,  ...,  0.6353, -0.1278, -0.0722],\n",
      "         [ 0.0763,  0.4924,  0.3183,  ..., -0.0632, -0.5141,  0.1628],\n",
      "         [ 0.1766,  0.2956,  0.4643,  ...,  0.0837, -0.4885,  0.3507],\n",
      "         [ 0.2602, -0.6544,  0.6046,  ..., -0.2466, -0.5448, -0.0928],\n",
      "         [ 0.3934, -0.0558,  0.2094,  ...,  0.9225, -1.0529, -0.2103]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "2-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 0.4482,  0.2891,  0.0266,  ...,  0.9235, -0.3312, -0.2826],\n",
      "         [ 0.1605,  0.6292,  0.4225,  ..., -0.5533, -0.4683,  0.3323],\n",
      "         [ 0.3686,  0.3184,  0.6038,  ..., -0.1233, -0.6612,  0.8132],\n",
      "         [ 1.1561, -1.1914,  0.6386,  ..., -0.2397, -0.7291, -0.2766],\n",
      "         [ 0.9492, -0.2455,  0.3244,  ...,  1.0966, -1.2796, -0.7396]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "3-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 0.6739, -0.2247,  0.0634,  ...,  0.7740, -0.2456, -0.1977],\n",
      "         [ 0.1363,  0.6261,  0.5552,  ..., -0.8053, -0.2070,  0.2352],\n",
      "         [ 0.3453,  0.4459,  0.7630,  ..., -0.3140, -0.4206,  0.7252],\n",
      "         [ 1.1627, -1.4497,  0.5902,  ..., -0.6079, -0.4785, -0.4936],\n",
      "         [ 1.0628,  0.2330,  0.3562,  ...,  1.1954, -1.4144, -1.1851]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "4-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.0433, -0.3935, -0.3980,  ...,  0.8048, -0.6424, -0.0279],\n",
      "         [ 0.6325,  0.6564,  0.4969,  ..., -1.0830, -0.0971,  0.7454],\n",
      "         [ 0.9524,  0.5130,  0.7141,  ..., -0.5048, -0.2757,  1.2844],\n",
      "         [ 1.1281, -1.7784,  0.8054,  ..., -0.8844, -0.0290,  0.0485],\n",
      "         [ 1.0171,  0.0053,  0.6924,  ...,  1.5686, -0.7045, -0.9908]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "5-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 0.6073, -0.8646, -0.2042,  ...,  0.4664, -0.4200,  0.1032],\n",
      "         [-0.1282,  0.2135,  0.5389,  ..., -1.4165,  0.0220,  0.7295],\n",
      "         [ 0.2643,  0.1923,  0.6040,  ..., -0.5364, -0.1441,  1.3042],\n",
      "         [ 0.8256, -2.0672,  0.4086,  ..., -0.8030,  0.3435,  0.2968],\n",
      "         [ 0.3913, -0.4786,  0.4776,  ...,  1.5554, -0.8200, -1.1065]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "6-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 7.6428e-01, -6.1017e-01, -5.3283e-01,  ...,  1.4212e-01,\n",
      "          -4.2147e-01,  1.0231e-01],\n",
      "         [-9.4916e-01, -8.3533e-02,  7.2676e-01,  ..., -1.8422e+00,\n",
      "           3.4058e-01,  1.2442e+00],\n",
      "         [-2.7649e-01,  7.1800e-02,  9.7629e-01,  ..., -5.2715e-01,\n",
      "           1.2864e-01,  1.5655e+00],\n",
      "         [ 9.4803e-01, -2.0538e+00,  6.9355e-01,  ...,  1.6731e-03,\n",
      "           3.7798e-01,  8.9397e-01],\n",
      "         [ 3.0228e-01, -4.9167e-01,  9.7387e-01,  ...,  2.5168e+00,\n",
      "          -4.2151e-01, -9.2217e-01]]], device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "7-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 0.8467, -0.5419, -0.2440,  ..., -0.8252, -0.3467, -0.0331],\n",
      "         [-1.2673, -0.4657,  0.7590,  ..., -1.8527,  0.1576,  1.8964],\n",
      "         [-0.4671, -0.3578,  1.0601,  ..., -0.4347,  0.0521,  1.9710],\n",
      "         [ 0.9037, -2.0645,  0.1031,  ...,  0.0300,  0.3542,  1.3607],\n",
      "         [-0.0903, -0.3920,  0.6324,  ...,  1.7244, -0.5687, -0.8141]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "8-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 0.6232, -0.9528, -0.8736,  ..., -2.1672, -0.3570, -0.2504],\n",
      "         [-1.5058, -0.6384,  0.6312,  ..., -2.5425,  0.6853,  2.0363],\n",
      "         [-1.0142, -0.4608,  1.1657,  ..., -0.8531,  0.4642,  2.2275],\n",
      "         [ 0.2064, -2.2963,  0.2131,  ...,  0.2649,  0.4983,  1.8706],\n",
      "         [-0.6073, -0.7283,  0.1377,  ...,  1.2617, -0.6388, -1.2273]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "9-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 0.7041, -1.2095, -1.1090,  ..., -3.2381, -0.4936, -0.5290],\n",
      "         [-1.7845, -0.7182,  0.3004,  ..., -2.5925,  0.3761,  1.7416],\n",
      "         [-1.0541, -0.6839,  1.1922,  ..., -0.7094,  0.3932,  1.7992],\n",
      "         [-0.1554, -2.6920, -0.0418,  ...,  0.2286,  0.2347,  1.6680],\n",
      "         [-0.3093, -1.4563, -0.1234,  ...,  1.1782, -1.0325, -1.7052]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "10-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 0.9081, -1.4079, -1.3142,  ..., -4.0250, -0.5933, -0.6156],\n",
      "         [-1.5907, -1.2080,  0.4305,  ..., -2.0228,  0.3772,  2.3962],\n",
      "         [-0.6424, -1.0642,  1.1991,  ..., -0.0905,  0.5495,  2.0537],\n",
      "         [-0.6005, -2.9268,  0.3469,  ...,  0.6928, -0.0738,  1.5682],\n",
      "         [-0.3689, -1.5168, -0.1682,  ...,  0.3264, -0.9935, -1.6321]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "11-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 0.9901, -1.4003, -1.4452,  ..., -4.5836, -0.5842, -0.7559],\n",
      "         [-2.0873, -1.2045,  0.4715,  ..., -2.4936,  0.4014,  2.4113],\n",
      "         [-1.2902, -0.7455,  0.9111,  ...,  0.0480,  0.3139,  2.0439],\n",
      "         [-1.0874, -2.3064,  0.8893,  ...,  0.2620, -0.2074,  2.4881],\n",
      "         [-0.5338, -2.3432, -0.1532,  ...,  0.4076, -0.9421, -0.9863]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "12-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.1525, -1.4799, -1.5087,  ..., -5.1192, -0.7151, -0.9405],\n",
      "         [-1.6842, -0.9689,  1.1814,  ..., -2.3948,  0.2855,  2.7374],\n",
      "         [-1.2063, -0.6478,  1.1957,  ...,  0.0671,  0.1941,  2.1385],\n",
      "         [-1.5400, -3.1920,  0.0527,  ...,  0.0567, -0.6715,  2.6699],\n",
      "         [-0.3419, -2.5710, -0.6219,  ...,  0.7794, -0.6926, -1.0808]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "13-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.2127, -1.5373, -1.5212,  ..., -5.6236, -0.6698, -0.9966],\n",
      "         [-1.6807, -1.1018,  1.1871,  ..., -2.7178,  0.3131,  2.9141],\n",
      "         [-1.0510, -0.3214,  0.9248,  ...,  0.3880,  0.4386,  1.5909],\n",
      "         [-1.6390, -3.0809, -0.8107,  ..., -0.3617, -1.1763,  3.0417],\n",
      "         [-0.6711, -1.9550, -1.1709,  ...,  1.4235, -1.7138, -0.7183]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "14-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.3348, -1.6375, -1.5572,  ..., -6.1412, -0.7801, -1.1308],\n",
      "         [-1.8116, -1.2146,  1.4890,  ..., -2.6127,  0.1078,  3.3024],\n",
      "         [-0.9928, -0.9243,  0.9874,  ...,  1.7382,  0.8153,  2.1696],\n",
      "         [-1.5266, -3.3230, -0.1935,  ..., -0.7574, -1.6921,  3.4888],\n",
      "         [-1.2900, -2.5081, -2.2743,  ...,  1.7426, -1.9568, -1.1886]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "15-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.4612, -1.6378, -1.6657,  ..., -6.7405, -0.8043, -1.2625],\n",
      "         [-1.3968, -1.5776,  1.2497,  ..., -2.8781,  0.0237,  3.3590],\n",
      "         [-0.5176, -0.6332,  0.7182,  ...,  1.7476,  0.4902,  2.0216],\n",
      "         [-0.7072, -3.8147, -0.5467,  ..., -0.7199, -2.9177,  3.3681],\n",
      "         [-1.0186, -2.2504, -2.9398,  ...,  2.0932, -2.3291, -1.8114]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "16-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.5189, -1.6385, -1.8020,  ..., -7.3200, -0.7068, -1.4318],\n",
      "         [-0.9408, -2.1665,  1.5695,  ..., -2.4318,  0.2079,  3.7381],\n",
      "         [ 0.3250, -0.9013,  0.1875,  ...,  1.9574, -0.0149,  2.8515],\n",
      "         [-0.4740, -3.8500, -0.5583,  ..., -1.4866, -3.2596,  4.0505],\n",
      "         [-0.8309, -1.9871, -3.2751,  ...,  2.5972, -1.7362, -2.0901]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "17-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.5871e+00, -1.6879e+00, -1.7728e+00,  ..., -8.0469e+00,\n",
      "          -6.5276e-01, -1.5884e+00],\n",
      "         [-8.6405e-01, -2.3289e+00,  1.4317e+00,  ..., -2.9732e+00,\n",
      "           2.6120e-01,  4.6151e+00],\n",
      "         [ 2.3112e+00, -4.0635e-01,  1.1219e+00,  ...,  2.1587e+00,\n",
      "          -9.7758e-04,  2.4647e+00],\n",
      "         [-2.7829e-01, -4.5709e+00, -4.9956e-01,  ..., -2.5627e+00,\n",
      "          -4.1009e+00,  4.5325e+00],\n",
      "         [-7.6622e-01, -2.9820e+00, -2.8784e+00,  ...,  1.7715e+00,\n",
      "          -1.0819e+00, -1.5670e+00]]], device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "18-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.8133, -1.6560, -1.6990,  ..., -8.8557, -0.6553, -1.6216],\n",
      "         [-0.6020, -1.9877,  2.0882,  ..., -2.8987, -0.2082,  4.4474],\n",
      "         [ 2.7224, -0.0474,  0.5421,  ...,  3.6644,  0.1319,  2.9790],\n",
      "         [-1.1266, -4.4531, -0.9364,  ..., -2.2524, -3.9738,  4.0063],\n",
      "         [-1.4525, -3.5739, -3.2250,  ...,  2.4770, -0.2156, -2.1354]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "19-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.9706, -1.7231, -1.7817,  ..., -9.5673, -0.5028, -1.6303],\n",
      "         [-0.2390, -1.7827,  2.2791,  ..., -2.4018, -0.1631,  4.5956],\n",
      "         [ 2.9360, -1.1202, -1.3777,  ...,  3.6787, -0.2926,  2.5508],\n",
      "         [-0.9102, -5.3809, -0.9510,  ..., -2.0513, -3.1039,  2.9758],\n",
      "         [-2.7915, -2.5708, -2.7273,  ...,  2.3872,  0.6549, -2.3039]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "20-th block:\n",
      "hidden_states:\n",
      " tensor([[[  2.0716,  -1.8719,  -1.7815,  ..., -10.3054,  -0.4238,  -1.7826],\n",
      "         [  0.2396,  -1.4904,   2.0938,  ...,  -2.1651,   0.3266,   4.5593],\n",
      "         [  3.6627,  -1.0639,  -2.5453,  ...,   4.5149,   0.3318,   4.1993],\n",
      "         [  0.5563,  -5.6188,  -0.9927,  ...,  -2.0198,  -2.9727,   3.4331],\n",
      "         [ -2.9752,  -2.7801,  -2.4951,  ...,   1.9970,   0.5850,  -2.3856]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "21-th block:\n",
      "hidden_states:\n",
      " tensor([[[  2.2045,  -1.9870,  -1.7532,  ..., -11.1246,  -0.2450,  -1.8158],\n",
      "         [  0.1816,  -2.1078,   2.0974,  ...,  -2.0420,  -0.1387,   5.3957],\n",
      "         [  3.6338,  -1.6588,  -1.9126,  ...,   5.0284,   0.0208,   4.8517],\n",
      "         [  0.4861,  -5.8852,  -1.2281,  ...,  -1.7191,  -3.1369,   3.5601],\n",
      "         [ -1.8847,  -3.0731,  -1.8242,  ...,   2.1391,   0.5531,  -1.8569]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "22-th block:\n",
      "hidden_states:\n",
      " tensor([[[  2.2771,  -2.0144,  -1.6531,  ..., -12.0033,  -0.0312,  -1.8473],\n",
      "         [ -0.3520,  -1.8819,   1.6331,  ...,  -2.3624,  -0.5589,   5.2948],\n",
      "         [  3.6529,  -1.8476,  -2.2516,  ...,   5.1718,   0.0268,   4.9713],\n",
      "         [  0.2032,  -5.5123,  -1.5363,  ...,  -1.6174,  -2.9464,   3.2582],\n",
      "         [ -1.3668,  -2.7324,  -2.0293,  ...,   1.6821,   0.4372,  -2.1359]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "23-th block:\n",
      "hidden_states:\n",
      " tensor([[[  2.2147,  -2.1375,  -1.5541,  ..., -12.7752,   0.1544,  -1.9270],\n",
      "         [ -0.7294,  -2.0839,   1.8739,  ...,  -3.5356,  -0.2130,   6.5166],\n",
      "         [  3.2520,  -2.0600,  -2.0446,  ...,   5.1655,  -0.6435,   6.1008],\n",
      "         [ -0.1053,  -5.5391,  -1.9386,  ...,  -2.1248,  -3.2229,   4.2163],\n",
      "         [ -0.1474,  -2.9772,  -1.9243,  ...,   1.5424,   0.6143,  -0.4256]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "24-th block:\n",
      "hidden_states:\n",
      " tensor([[[  2.1809,  -2.2725,  -1.5404,  ..., -13.4856,   0.3733,  -1.9943],\n",
      "         [ -0.7230,  -2.0772,   1.8333,  ...,  -3.8610,  -0.1456,   6.6818],\n",
      "         [  4.0056,  -3.0271,  -3.1971,  ...,   5.1112,  -1.6965,   7.0008],\n",
      "         [ -0.6284,  -5.6282,  -1.5464,  ...,  -3.0912,  -3.8124,   4.7019],\n",
      "         [ -0.6786,  -3.7500,  -2.0766,  ...,   1.7090,   1.4516,   0.4670]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "25-th block:\n",
      "hidden_states:\n",
      " tensor([[[  2.0872,  -2.4726,  -1.5161,  ..., -14.0777,   0.6536,  -1.9228],\n",
      "         [ -0.6707,  -2.5054,   1.8181,  ...,  -4.2809,   0.9931,   6.7123],\n",
      "         [  4.2834,  -4.2008,  -2.8169,  ...,   6.1314,  -0.2377,   7.7681],\n",
      "         [ -0.9327,  -5.7726,  -2.3902,  ...,  -2.4287,  -3.9952,   4.6930],\n",
      "         [ -1.3793,  -3.5354,  -2.6231,  ...,   3.5170,   1.2296,   0.0650]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "26-th block:\n",
      "hidden_states:\n",
      " tensor([[[  2.0337,  -2.4067,  -1.4163,  ..., -14.6159,   0.9933,  -2.0003],\n",
      "         [  0.0597,  -2.5074,   1.9335,  ...,  -3.6485,   1.4321,   7.1715],\n",
      "         [  4.2298,  -5.2663,  -3.1962,  ...,   6.7683,  -0.5940,   8.6633],\n",
      "         [ -0.4793,  -5.8156,  -0.8971,  ...,  -2.7049,  -3.5207,   4.7242],\n",
      "         [ -2.0091,  -3.5331,  -1.7406,  ...,   3.9649,   2.0635,   0.6971]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "27-th block:\n",
      "hidden_states:\n",
      " tensor([[[  2.0090,  -2.4831,  -1.4322,  ..., -15.1715,   1.3717,  -2.1287],\n",
      "         [  0.1289,  -2.4073,   1.5165,  ...,  -2.8556,   1.5796,   8.0074],\n",
      "         [  2.7830,  -6.1093,  -4.1762,  ...,   7.4711,  -1.6375,   9.5402],\n",
      "         [ -1.6129,  -6.6353,  -2.1841,  ...,  -2.4502,  -3.0252,   5.1607],\n",
      "         [ -4.2007,  -4.1777,  -2.1846,  ...,   4.4892,   2.0574,   0.2562]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "28-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.9423,  -2.5353,  -1.2772,  ..., -16.0645,   1.6217,  -2.1031],\n",
      "         [ -1.0639,  -4.0255,   2.8540,  ...,  -3.1408,   2.0379,   9.2547],\n",
      "         [  2.3933,  -6.3373,  -3.1537,  ...,   6.6313,  -1.6644,  11.2863],\n",
      "         [ -2.3265,  -8.2499,  -1.9874,  ...,  -3.0673,  -3.7794,   5.8158],\n",
      "         [ -3.6810,  -4.6102,  -1.9985,  ...,   4.8081,   2.5284,   0.4332]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "29-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.9138,  -2.6512,  -1.2352,  ..., -17.0939,   1.8761,  -2.1192],\n",
      "         [ -0.4236,  -4.9274,   4.3681,  ...,  -3.6484,   3.5803,  10.4061],\n",
      "         [  3.0631,  -7.0566,  -2.7762,  ...,   5.7978,  -1.0379,  12.8311],\n",
      "         [ -2.7299,  -9.1012,  -2.3800,  ...,  -4.0507,  -3.7632,   6.1131],\n",
      "         [ -3.0425,  -5.5139,  -3.0916,  ...,   5.0931,   2.2181,  -0.0234]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "30-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.8413,  -2.7684,  -1.1495,  ..., -18.1566,   2.1880,  -2.0017],\n",
      "         [ -2.1154,  -5.5894,   5.4296,  ...,  -2.9833,   3.6989,  11.5979],\n",
      "         [  1.9796,  -7.6275,  -1.5011,  ...,   5.6410,  -0.8601,  13.1369],\n",
      "         [ -4.1151, -10.2441,  -1.4225,  ...,  -2.9745,  -3.6378,   8.1594],\n",
      "         [ -4.4575,  -6.0326,  -2.8881,  ...,   6.2692,   2.6985,   0.8039]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "31-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.7685,  -2.8599,  -1.1668,  ..., -19.6170,   2.4601,  -1.9896],\n",
      "         [ -2.2283,  -5.0266,   5.8970,  ...,  -3.0330,   5.4016,  11.9575],\n",
      "         [  0.9821,  -8.6277,  -0.8649,  ...,   7.3668,   1.5502,  13.9386],\n",
      "         [ -3.9091, -11.3434,  -1.8109,  ...,  -4.3606,  -1.7550,   8.5909],\n",
      "         [ -4.3228,  -5.9118,  -2.1359,  ...,   5.5774,   2.5042,   0.4766]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "32-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.5926,  -2.8941,  -1.0680,  ..., -21.0248,   2.8448,  -1.9434],\n",
      "         [ -2.7594,  -5.5752,   7.8109,  ...,  -3.4363,   5.1496,  13.2294],\n",
      "         [  1.3389,  -9.5415,  -0.8525,  ...,   5.8917,   1.6618,  15.1729],\n",
      "         [ -3.0100, -12.8403,  -3.5768,  ...,  -6.5780,  -1.3215,  10.6789],\n",
      "         [ -4.4081,  -6.7176,  -2.4462,  ...,   4.9258,   3.4618,   1.6955]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "33-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.6538,  -2.8931,  -0.8866,  ..., -22.6321,   2.9267,  -1.9242],\n",
      "         [ -3.1154,  -6.1441,   8.4577,  ...,  -3.5798,   6.5722,  14.8230],\n",
      "         [  1.5815, -10.4104,  -0.3464,  ...,   4.8402,   2.9055,  15.9979],\n",
      "         [ -2.2112, -14.5590,  -4.0011,  ...,  -8.4163,  -0.4990,  11.0897],\n",
      "         [ -3.6985,  -7.0306,  -2.3871,  ...,   4.9283,   2.5067,   2.4015]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "34-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.6629,  -2.8018,  -0.7524,  ..., -24.3993,   3.2433,  -1.8534],\n",
      "         [ -2.2681,  -6.9896,   9.5148,  ...,  -4.4042,   7.9873,  16.4487],\n",
      "         [  0.8178, -11.4152,   1.5142,  ...,   3.6397,   4.0050,  17.9755],\n",
      "         [ -3.1149, -16.9000,  -4.4553,  ..., -10.7888,   1.4003,  12.0041],\n",
      "         [ -4.4967,  -7.6184,  -2.4016,  ...,   4.4439,   2.4349,   2.9640]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "35-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.6101,  -2.7561,  -0.5074,  ..., -26.4687,   3.4325,  -1.8108],\n",
      "         [ -3.5593,  -6.8876,  10.1435,  ...,  -4.9654,   8.9004,  15.9574],\n",
      "         [  0.6227, -11.2084,   2.1772,  ...,   3.8720,   4.3764,  18.5436],\n",
      "         [ -3.6506, -18.0683,  -3.9657,  ..., -12.1246,   2.5982,  12.4569],\n",
      "         [ -5.5031,  -8.1682,  -3.8202,  ...,   3.6190,   1.3012,   4.0455]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "36-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.4733,  -2.8919,  -0.4792,  ..., -29.0305,   3.5514,  -1.7494],\n",
      "         [ -4.4909,  -7.1707,  10.3132,  ...,  -5.9767,  10.4164,  16.7464],\n",
      "         [ -1.9956, -11.1269,   0.8572,  ...,   2.8869,   6.1215,  19.9098],\n",
      "         [ -5.0344, -18.2498,  -5.4569,  ..., -13.3187,   3.0698,  13.4328],\n",
      "         [ -7.6493, -10.1577,  -5.2308,  ...,   1.7573,   2.5432,   2.9352]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "37-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.4412,  -2.7038,  -0.3858,  ..., -32.3108,   3.5841,  -1.7566],\n",
      "         [ -3.8961,  -5.6968,   9.9879,  ...,  -5.5811,  12.4660,  17.9080],\n",
      "         [ -2.8190, -10.8001,   1.4898,  ...,   4.2717,   7.1387,  20.4665],\n",
      "         [ -6.8469, -19.0627,  -4.8216,  ..., -14.8568,   3.3375,  12.5147],\n",
      "         [ -8.2979, -10.9962,  -6.0797,  ...,   1.9360,   1.9655,   1.5436]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "38-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.4082,  -2.6538,  -0.1354,  ..., -35.5069,   3.6785,  -1.5937],\n",
      "         [ -3.6378,  -5.1656,  10.2055,  ...,  -4.5341,  13.1487,  18.0597],\n",
      "         [ -1.8326, -12.3061,   1.0242,  ...,   4.6809,   7.2386,  20.9324],\n",
      "         [ -6.0449, -21.0281,  -6.2199,  ..., -17.7090,   4.2107,  12.0191],\n",
      "         [ -8.2230, -12.9812,  -7.8745,  ...,  -1.4153,   2.8022,   0.9145]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "39-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.3940e+00, -2.5915e+00,  3.9083e-02,  ..., -4.0030e+01,\n",
      "           3.7126e+00, -1.4499e+00],\n",
      "         [-5.1517e+00, -5.7191e+00,  1.1301e+01,  ..., -4.0479e+00,\n",
      "           1.4638e+01,  1.8082e+01],\n",
      "         [-3.0700e+00, -1.3576e+01,  2.7002e+00,  ...,  5.9699e+00,\n",
      "           8.4806e+00,  1.9974e+01],\n",
      "         [-4.6379e+00, -2.2815e+01, -5.7451e+00,  ..., -1.9272e+01,\n",
      "           5.1662e+00,  1.2544e+01],\n",
      "         [-9.4082e+00, -1.5022e+01, -7.9781e+00,  ..., -4.1205e+00,\n",
      "           3.0173e+00, -1.0316e+00]]], device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "40-th block:\n",
      "hidden_states:\n",
      " tensor([[[  1.2399,  -2.4870,   0.2609,  ..., -46.0430,   3.7411,  -1.3883],\n",
      "         [ -5.1525,  -5.4935,  13.1170,  ...,  -3.9615,  15.5712,  18.0954],\n",
      "         [ -4.3125, -13.3541,   4.0451,  ...,   5.8048,  10.2038,  20.6646],\n",
      "         [ -5.9360, -22.6390,  -5.6904,  ..., -22.3545,   4.9858,  13.1989],\n",
      "         [ -9.4108, -14.9934,  -8.9592,  ...,  -9.0213,   5.3436,   1.1036]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "41-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 1.1113e+00, -2.4799e+00,  4.7506e-01,  ..., -5.5695e+01,\n",
      "           4.0262e+00, -1.3852e+00],\n",
      "         [-4.8326e+00, -5.4076e+00,  1.2827e+01,  ..., -5.8070e+00,\n",
      "           1.6325e+01,  1.9120e+01],\n",
      "         [-4.5654e+00, -1.4288e+01,  3.3347e+00,  ...,  4.6451e+00,\n",
      "           1.0879e+01,  2.0807e+01],\n",
      "         [-7.7578e+00, -2.3251e+01, -5.7155e+00,  ..., -2.5706e+01,\n",
      "           6.7691e+00,  1.3636e+01],\n",
      "         [-1.2220e+01, -1.4965e+01, -1.0237e+01,  ..., -1.2180e+01,\n",
      "           5.0792e+00,  1.1367e-02]]], device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "42-th block:\n",
      "hidden_states:\n",
      " tensor([[[  0.9584,  -2.4381,   0.6519,  ..., -69.7913,   4.3389,  -1.3724],\n",
      "         [ -5.5632,  -4.0191,  13.5242,  ...,  -8.2606,  17.9734,  19.7998],\n",
      "         [ -4.8433, -13.8453,   4.2722,  ...,   2.1628,  11.7334,  22.3283],\n",
      "         [ -7.3753, -24.8568,  -5.1363,  ..., -31.2873,   6.9595,  12.2838],\n",
      "         [-11.9895, -17.6770, -10.9573,  ..., -21.2671,   6.3878,  -1.5054]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "43-th block:\n",
      "hidden_states:\n",
      " tensor([[[  0.8093,  -2.3474,   0.9658,  ..., -88.4945,   4.6208,  -1.3160],\n",
      "         [ -5.2847,  -4.0019,  14.0470,  ..., -13.7975,  20.1582,  21.4736],\n",
      "         [ -4.7901, -12.8564,   3.6418,  ...,  -3.2581,  12.3918,  23.2316],\n",
      "         [ -8.4004, -26.2680,  -4.6103,  ..., -37.3216,   7.6102,  11.1118],\n",
      "         [-13.1188, -18.9790,  -8.8294,  ..., -32.0422,   7.2933,  -3.1866]]],\n",
      "       device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "44-th block:\n",
      "hidden_states:\n",
      " tensor([[[   0.6063,   -2.2592,    1.2503,  ..., -111.0854,    4.8466,\n",
      "            -1.2675],\n",
      "         [  -4.8724,   -2.4883,   16.2595,  ...,  -22.2848,   20.4559,\n",
      "            20.8609],\n",
      "         [  -4.3476,  -11.3986,    5.1011,  ...,   -9.9522,   12.6461,\n",
      "            22.5298],\n",
      "         [  -8.0369,  -26.4809,   -2.6979,  ...,  -48.0342,    9.9503,\n",
      "            11.3072],\n",
      "         [ -15.1904,  -21.0165,   -9.9033,  ...,  -54.9788,    8.6600,\n",
      "            -3.6916]]], device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "45-th block:\n",
      "hidden_states:\n",
      " tensor([[[   0.4813,   -1.9624,    1.4568,  ..., -137.3887,    5.1879,\n",
      "            -1.0456],\n",
      "         [  -3.2945,   -0.8511,   16.5706,  ...,  -41.8678,   22.7400,\n",
      "            21.8601],\n",
      "         [  -4.3178,  -11.4657,    4.8567,  ...,  -29.7732,   16.2187,\n",
      "            23.5555],\n",
      "         [  -6.5782,  -25.7035,   -1.7798,  ...,  -73.2254,    8.7216,\n",
      "            11.4178],\n",
      "         [ -14.9488,  -22.1614,   -9.8910,  ..., -113.9679,    8.2129,\n",
      "            -3.9242]]], device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "46-th block:\n",
      "hidden_states:\n",
      " tensor([[[   0.4606,   -1.7013,    1.7689,  ..., -169.0663,    5.1391,\n",
      "            -0.4380],\n",
      "         [  -2.7007,   -1.2794,   17.1994,  ...,  -86.5190,   23.7342,\n",
      "            22.9600],\n",
      "         [  -3.9845,  -12.8626,    4.9403,  ...,  -74.8598,   18.3965,\n",
      "            23.8209],\n",
      "         [  -5.9731,  -25.8963,   -0.8231,  ..., -127.1464,    9.9420,\n",
      "            11.4953],\n",
      "         [ -12.8057,  -19.7645,   -8.4548,  ..., -207.0921,    9.8001,\n",
      "            -2.3882]]], device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "47-th block:\n",
      "hidden_states:\n",
      " tensor([[[ 9.5083e-02, -2.3831e+00,  2.1909e+00,  ..., -1.9170e+02,\n",
      "           3.8292e+00,  3.9940e-01],\n",
      "         [-1.6284e-01, -1.2139e+00,  1.8010e+01,  ..., -1.3301e+02,\n",
      "           2.3765e+01,  2.1927e+01],\n",
      "         [-2.2931e+00, -1.2885e+01,  6.8072e+00,  ..., -1.3933e+02,\n",
      "           2.0551e+01,  2.2326e+01],\n",
      "         [-4.2049e+00, -2.4622e+01,  2.4278e+00,  ..., -1.8682e+02,\n",
      "           1.0279e+01,  1.1017e+01],\n",
      "         [-1.0301e+01, -1.8683e+01, -7.1769e+00,  ..., -2.9449e+02,\n",
      "           1.0683e+01, -2.6428e+00]]], device='cuda:0')\n",
      "layer_past: None\n",
      "head_mask: None\n",
      "hidden_states: torch.Size([1, 5, 1600])\n"
     ]
    }
   ],
   "source": [
    "def gpt2_transformer_forward(model, input_ids):\n",
    "    print(\"input_ids.shape:\",input_ids.shape)\n",
    "    model.eval()\n",
    "    input_shape = input_ids.size()\n",
    "    # (batch_size*seq_len, hidden_size)\n",
    "    input_ids = input_ids.view(-1, input_shape[-1])  \n",
    "    batch_size = input_ids.shape[0]\n",
    "\n",
    "    # 上一回合缓存的kv-cache\n",
    "    past_key_values = tuple([None]*len(model.h)) # (None)*48, dtype = tuple\n",
    "    \n",
    "    # 构造位置 id\n",
    "    # 从past_length开始，长为hidden_size的一维向量，并转换为二维向量\n",
    "    past_length = 0\n",
    "    position_ids = torch.arange(past_length, input_shape[-1]+past_length, dtype=torch.long, device=device)\n",
    "    position_ids = position_ids.unsqueeze(0).view(-1, input_shape[-1])\n",
    "\n",
    "    encoder_attention_mask = None\n",
    "\n",
    "    # embedding\n",
    "    input_embeds = model.wte(input_ids)\n",
    "    position_embeds = model.wpe(position_ids)\n",
    "    hidden_states = input_embeds + position_embeds\n",
    "    output_shape = input_shape + (hidden_states.size(-1),)\n",
    "    print(\"output_shape:\",output_shape)\n",
    "\n",
    "    head_mask = model.get_head_mask(None, model.config.n_layer)# [None]*48, dtype = list\n",
    "    print(\"head_mask:\",head_mask)\n",
    "\n",
    "    for i, (block, layer_past) in enumerate(zip(model.h, past_key_values)):\n",
    "        print(f\"{i}-th block:\")\n",
    "        print(\"hidden_states:\\n\",hidden_states)\n",
    "        print(\"layer_past:\",layer_past)\n",
    "        print(\"head_mask:\",head_mask[i])\n",
    "\n",
    "        outputs = block(\n",
    "            hidden_states,\n",
    "            layer_past=layer_past,\n",
    "            head_mask=head_mask[i]\n",
    "        )\n",
    "        # 这一层输出当作下一层输入\n",
    "        hidden_states = outputs[0]\n",
    "        print(\"hidden_states:\",hidden_states.shape)\n",
    "    # 最终输出\n",
    "    hidden_states = model.ln_f(hidden_states)\n",
    "    hidden_states = hidden_states.view(output_shape)\n",
    "    return hidden_states\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = gpt2_transformer_forward(model_clm.transformer, input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09bfa1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1600])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7527de",
   "metadata": {},
   "source": [
    "lmhead_model(input_ids)\n",
    "- logits\n",
    "- past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf4a4331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5445,  2.5812,  0.6197,  ..., -7.4777, -5.5282,  0.6108],\n",
       "         [ 1.0344,  1.5582, -2.5840,  ..., -6.3941, -2.5380, -1.0215],\n",
       "         [ 2.0070,  2.3330, -1.1671,  ..., -7.7938, -3.9385,  1.0949],\n",
       "         [ 5.6171,  4.4350, -2.1919,  ..., -7.9733, -5.2310,  1.6343],\n",
       "         [ 4.8450,  5.3529, -0.7294,  ..., -7.7071, -3.8473,  2.5437]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clm(input_ids).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7eb0c7",
   "metadata": {},
   "source": [
    "自定义 lmhead_model forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bac6dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt2_clm_forward(model, input_ids):\n",
    "    model.eval()\n",
    "    transformer_outputs = model.transformer(input_ids)\n",
    "    hidden_states = transformer_outputs[0]\n",
    "    print(\"hidden_states:\",hidden_states.shape)\n",
    "    logits = model.lm_head(hidden_states)\n",
    "    print(\"logits:\",logits.shape)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24321204",
   "metadata": {},
   "source": [
    "model_clm.transformer输出\n",
    "- last_hidden_state\n",
    "- past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed5dcc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states: torch.Size([1, 5, 1600])\n",
      "logits: torch.Size([1, 5, 50257])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5445,  2.5812,  0.6197,  ..., -7.4777, -5.5282,  0.6108],\n",
       "         [ 1.0344,  1.5582, -2.5840,  ..., -6.3941, -2.5380, -1.0215],\n",
       "         [ 2.0070,  2.3330, -1.1671,  ..., -7.7938, -3.9385,  1.0949],\n",
       "         [ 5.6171,  4.4350, -2.1919,  ..., -7.9733, -5.2310,  1.6343],\n",
       "         [ 4.8450,  5.3529, -0.7294,  ..., -7.7071, -3.8473,  2.5437]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_clm_forward(model_clm, input_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTroch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
